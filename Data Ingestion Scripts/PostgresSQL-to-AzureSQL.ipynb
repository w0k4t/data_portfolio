{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load vodka data\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pyodbc\n",
    "# Database connection details\n",
    "db_user = 'postgres'\n",
    "db_password = 'password'\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'lca'\n",
    "schema_name = 'PED'  # Specify schema here\n",
    "\n",
    "# Create a connection string to postgres\n",
    "postgres_conn = f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}'\n",
    "postgres_local = create_engine(postgres_conn)\n",
    "\n",
    "azure_conn = \"Driver={ODBC Driver 18 for SQL Server};Server=tcp:<hostname>.database.windows.net,1433;Database=<dbname>;Uid=<username>;Pwd=<super secret password>;Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\"\n",
    "# Create an engine object\n",
    "azure = create_engine(f\"mssql+pyodbc:///?odbc_connect={azure_conn}\")\n",
    "\n",
    "# Define your SQL query\n",
    "query = 'SELECT * FROM \"PED\".vodka_sales'\n",
    "\n",
    "# Read data in chunks\n",
    "chunksize = 100000  # Number of rows per chunk\n",
    "counter=1\n",
    "for chunk in pd.read_sql(query, postgres_local, chunksize=chunksize):\n",
    "    # Process each chunk\n",
    "    print(\"chunk#= \",counter,\"aprox:\",counter*chunksize)\n",
    "    # Load DataFrame to Azure SQL with schema\n",
    "    chunk.to_sql('vodka_sales', azure, schema='dbo', if_exists='append', index=False)\n",
    "    counter+=1\n",
    "    \n",
    "print(\"File loaded to Azure SQL DB successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
