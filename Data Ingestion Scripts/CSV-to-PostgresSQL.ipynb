{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7d1a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "arr = os.listdir('data/Base Tables/')\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd82308",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_path = os.listdir('data/Sales Data')\n",
    "sales_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecae7f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Database connection details\n",
    "db_user = 'postgres'\n",
    "db_password = 'admin'\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'lastcall'\n",
    "schema_name = 'PED'  # Specify your schema here\n",
    "\n",
    "# Create a connection string\n",
    "connection_string = f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}'\n",
    "\n",
    "# Create an engine\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "for file in sales_path:\n",
    "    print(\"Loading : \",file[:-4])\n",
    "    file_path=f'data/Sales Data/{file}'\n",
    "    chunk_size = 1000000  # Adjust this number based on your needs#\n",
    "    ## Create an iterator to read the CSV file in chunks\n",
    "    csv_iterator = pd.read_csv(file_path, chunksize=chunk_size)\n",
    "#    ## Process each chunk\n",
    "    counter=1\n",
    "    status=1000000\n",
    "    \n",
    "    for chunk in csv_iterator:\n",
    "        # Perform operations on each chunk \n",
    "        # Load DataFrame to PostgreSQL with schema\n",
    "        chunk.to_sql(file[:-4], engine, schema=schema_name, if_exists='append', index=False)\n",
    "        print(f\"Chunk#{counter}- Rows {status}\")\n",
    "        counter+=1\n",
    "        status+=1000000\n",
    "\n",
    "print(\"File loaded to PostgreSQL successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f8d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "# Database connection details\n",
    "db_user = 'postgres'\n",
    "db_password = 'admin'\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'lastcall'\n",
    "schema_name = 'PED'  # Specify your schema here\n",
    "\n",
    "# Create a connection string\n",
    "connection_string = f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}'\n",
    "\n",
    "# Create an engine object\n",
    "engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={connection_string}\")\n",
    "\n",
    "for file in arr:\n",
    "    print(\"Loading : \",file[:-4])\n",
    "    file_path=f'data/Base Tables/{file}'\n",
    "    ## Create an iterator to read the CSV file in chunks\n",
    "    df=pd.read_csv(file_path, chunksize=chunk_size)\n",
    "    df.to_sql(file[:-4], engine, schema=schema_name, if_exists='replace', index=False)\n",
    "\n",
    "print(\"File loaded to Postgres SQL DB successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
